{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-Finetune_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUMXsZ7_caLi",
        "outputId": "e8784307-5909-45cc-a843-1e24f33fe216"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK_ud_NAka_4"
      },
      "source": [
        "#!curl -q https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "#!python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n",
        "!pip -q install seqeval\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JYeja6oJECbT",
        "outputId": "4c934e16-ed37-4dcd-f789-ce5dd43b4639"
      },
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbxud-ymEJUN"
      },
      "source": [
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import json\n",
        "from collections import defaultdict, OrderedDict\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "random.seed(1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro4_Bu7OhWsF",
        "outputId": "b96aada7-9c12-463b-b447-7e5ca6d2aad4"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHzHqMC6xZPt"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForTokenClassification, BertTokenizer, BertConfig, BertModel"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8_3MXovhaL4"
      },
      "source": [
        "## Initialize GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYfoSkauEOWE",
        "outputId": "e6c6b110-2522-4e27-b608-c38d371adb5c"
      },
      "source": [
        "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "dev"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UWhZubSK2FO"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj3ebBppKy6H",
        "outputId": "c65c99db-f332-4552-c8eb-95294e3ecc00"
      },
      "source": [
        "# Read export file\n",
        "with open('/content/drive/MyDrive/ML_Models/Bi-LSTM/doccano_output.jsonl', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "print(json.loads(lines[30]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 11178, 'data': 'In 2020, we launched two new Workshop-wide task forces.2 Weve never had anything like this, says Rosemarie Truglio, SVP of curriculum and content. These efforts will affect everyones work, growth, and development.', 'label': [[116, 120, 'B-POS'], [114, 116, 'O'], [107, 114, 'I-PER'], [97, 107, 'B-PER'], [0, 3, 'O'], [3, 7, 'O'], [7, 9, 'O'], [9, 12, 'O'], [12, 21, 'O'], [21, 25, 'O'], [25, 29, 'O'], [29, 42, 'O'], [43, 48, 'O'], [48, 54, 'O'], [55, 57, 'O'], [54, 55, 'O'], [57, 62, 'O'], [62, 68, 'O'], [68, 72, 'O'], [72, 81, 'O'], [81, 86, 'O'], [86, 90, 'O'], [90, 92, 'O'], [92, 97, 'O'], [120, 123, 'I-POS'], [123, 134, 'I-POS'], [134, 138, 'I-POS'], [138, 145, 'I-POS'], [145, 147, 'O'], [147, 153, 'O'], [153, 161, 'O'], [161, 166, 'O'], [166, 173, 'O'], [173, 183, 'O'], [183, 187, 'O'], [187, 189, 'O'], [189, 195, 'O'], [195, 197, 'O'], [197, 201, 'O'], [201, 212, 'O'], [212, 213, 'O']]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFWDJvyws_x9"
      },
      "source": [
        "### Read in from JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpsEEPnPlRaW"
      },
      "source": [
        "# The numerical doccano label to actual label (B-I-O scheme)\n",
        "\n",
        "ix_to_label = {1: 'B-PER', 2: 'I-PER', 3:'B-POS', 4:'I-POS', 5:'B-ORG', 6: 'I-ORG', 7: 'O'}\n",
        "    \n",
        "# train/test data\n",
        "data = []\n",
        "\n",
        "# Vocabulary\n",
        "vocab = set()\n",
        "    \n",
        "# Loop over each data point (a corpus of labeled text) to extract words\n",
        "for line in lines:\n",
        "\n",
        "    # An ordered dict will keep items in order for further manipulation\n",
        "    # so we initialize here\n",
        "    orddict = OrderedDict({})\n",
        "\n",
        "    # Lists to hold the words and labels\n",
        "    words = []\n",
        "    labels = []\n",
        "    # Convert line to json\n",
        "    input_json = json.loads(line)\n",
        "    annots = input_json['label']\n",
        "    text = input_json['data']\n",
        "    \n",
        "    # Add each word annotation to OrderedDict\n",
        "    for ann in annots:\n",
        "        orddict[ann[0]] = ann\n",
        "    \n",
        "    # Sort ordered dict\n",
        "    # maintained order\n",
        "    orddict = sorted(orddict.items(), key=lambda x: x[1][0])\n",
        "    \n",
        "    for item in orddict:\n",
        "        # the item is a tuple where second value is the actual value we want\n",
        "        ann = item[1]\n",
        "        # Subset text string\n",
        "        word = text[ann[0]:(ann[1])].rstrip()\n",
        "        label = ann[2]\n",
        "        # Add to list for this datum/corpus\n",
        "        words.append(word)\n",
        "        labels.append(label)\n",
        "        vocab.add(word)\n",
        "    # Add to overall data containers\n",
        "    data.append((words, labels))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiyHbZsIgRAm",
        "outputId": "9c33e684-fc17-437d-f940-372b8c597b25"
      },
      "source": [
        "slens = [len(data[i][0]) for i in range(len(data))]\n",
        "max(slens)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdAByBCEtGqF"
      },
      "source": [
        "## Reassemble sentences and tag-mappings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTvF4Uq7lUwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf8a6d1-4f4e-4ff1-9e5e-d471358ef6d1"
      },
      "source": [
        "ix_to_label = {0: 'B-PER', 1: 'I-PER', 2:'B-POS', 3:'I-POS', 4:'B-ORG', 5: 'I-ORG', 6: 'O'}\n",
        "tags_vals = [v for k,v in ix_to_label.items()]\n",
        "tag2idx = {t: i for i, t in ix_to_label.items()}\n",
        "sentences = [' '.join([s for s in sent[0]]) for sent in data]\n",
        "labels = [[s for s in sent[1]] for sent in data]\n",
        "labels = [[tag2idx.get(l) for l in lab] for lab in labels]\n",
        "print(tag2idx)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'B-PER': 0, 'I-PER': 1, 'B-POS': 2, 'I-POS': 3, 'B-ORG': 4, 'I-ORG': 5, 'O': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N56IBfJej2Lr"
      },
      "source": [
        "## BERT-BASE-CASED\n",
        "\n",
        "Before we can begin fine-tuning our model, we have to establish a few environment variables and hyper parameters that we will be using in our model and use a few of these to create a `CustomDataset` that can be used by the models in the HuggingFace library. \n",
        "\n",
        "A principle component of this dataset is the tokenizer that we will be using, as the embeddings of the tokenizer have to match the embeddings expected by the model. In this case we will be using `bert-base-cased` to tokenize and extract entities from our input sentences.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1p6rkMdj9s3"
      },
      "source": [
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = max(slens)\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 2e-05\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsa-9Fmxtyif"
      },
      "source": [
        "### Assemble Data-loader\n",
        "\n",
        "In addition to the tokenizer above, the other essential components of our `CustomDataset` are the input sentences themselves, their labels, and the lengths of each sequence (as well as the max_sequence length, which we will use to pad the shorter sequences). Additionally, as part of the requirements for evaluating sequences in the transformer architecture, the tokenizer we provided also outputs the `attention_mask` for each sequence that will be used during training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB_a_25TkDDp"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, tokenizer, sentences, labels, max_len):\n",
        "        self.len = len(sentences)\n",
        "        self.sentences = sentences\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        sentence = str(self.sentences[index])\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            sentence,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length = True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        label = self.labels[index]\n",
        "        label.extend([6]*MAX_LEN)\n",
        "        label=label[:MAX_LEN]\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'tags': torch.tensor(label, dtype=torch.long)\n",
        "        } \n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bABMhxATwUyo"
      },
      "source": [
        "### Train/test splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW7unUMWprE_",
        "outputId": "5b137ecc-4759-4aba-a0a2-effd07e19ac1"
      },
      "source": [
        "train_percent = 0.8\n",
        "train_size = int(train_percent*len(sentences))\n",
        "# train_dataset=df.sample(frac=train_size,random_state=200).reset_index(drop=True)\n",
        "# test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_sentences = sentences[0:train_size]\n",
        "train_labels = labels[0:train_size]\n",
        "\n",
        "test_sentences = sentences[train_size:]\n",
        "test_labels = labels[train_size:]\n",
        "print(labels[1])\n",
        "print(\"FULL Dataset: {}\".format(len(sentences)))\n",
        "print(\"TRAIN Dataset: {}\".format(len(train_sentences)))\n",
        "print(\"TEST Dataset: {}\".format(len(test_sentences)))\n",
        "\n",
        "training_set = CustomDataset(tokenizer, train_sentences, train_labels, MAX_LEN)\n",
        "testing_set = CustomDataset(tokenizer, test_sentences, test_labels, MAX_LEN)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 6, 4, 6]\n",
            "FULL Dataset: 108\n",
            "TRAIN Dataset: 86\n",
            "TEST Dataset: 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1hF_HqHwR2O"
      },
      "source": [
        "AUTHOR NOTE: As we can see from above, we do not have a lot of observations for fine-tuning the model, this is also the case for the BiLSTM-CRF that we train in a separate notebook, so for comparisons sake, this is an adequate dataset, but for productionalizing this model, a larger dataset is most certainly beneficial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-DH8mklL7AP"
      },
      "source": [
        "### Create Dataloader for Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fvhm2cptL44b"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxerfqWXw3B1",
        "outputId": "6934c031-5f1b-4572-ab39-568f6956fb4e"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1490"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XwP0bgQGlN6"
      },
      "source": [
        "## Train\n",
        "\n",
        "### Create Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2u39zclu19bQ"
      },
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        seq - the sequence (array)\n",
        "        to_ix - the indices to which seqence values are converted (dict)\n",
        "\n",
        "    Output:\n",
        "        Numerical tensor\n",
        "        \"\"\"\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXp_V5DbqF4l"
      },
      "source": [
        "class BERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTClass, self).__init__()\n",
        "        self.l1 = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=7)\n",
        "        # self.l2 = torch.nn.Dropout(0.3)\n",
        "        # self.l3 = torch.nn.Linear(768, 200)\n",
        "    \n",
        "    def forward(self, ids, mask, labels):\n",
        "        output_1= self.l1(ids, mask, labels = labels)\n",
        "        # output_2 = self.l2(output_1[0])\n",
        "        # output = self.l3(output_2)\n",
        "        return output_1"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7hsZ7TOqMX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d271981d-25af-4bba-9886-29d131622c94"
      },
      "source": [
        "model = BERTClass()\n",
        "#model = BERT_CRF(tag2idx)\n",
        "model.to(dev)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (l1): BertForTokenClassification(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBd-j8pJqP_6"
      },
      "source": [
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z3qJESSqoTM"
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(dev, dtype = torch.long)\n",
        "        mask = data['mask'].to(dev, dtype = torch.long)\n",
        "        targets = data['tags'].to(dev, dtype = torch.long)\n",
        "\n",
        "        loss = model(ids, mask, labels = targets)[0]\n",
        "\n",
        "        # optimizer.zero_grad()\n",
        "        if _%500==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VlFLReerONa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c584b151-2266-40e2-d3bd-1720abcab1a1"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss:  2.013887643814087\n",
            "Epoch: 1, Loss:  0.901118814945221\n",
            "Epoch: 2, Loss:  0.5377925634384155\n",
            "Epoch: 3, Loss:  0.5462907552719116\n",
            "Epoch: 4, Loss:  0.7439249157905579\n",
            "Epoch: 5, Loss:  0.4618852436542511\n",
            "Epoch: 6, Loss:  0.48518505692481995\n",
            "Epoch: 7, Loss:  0.6461377143859863\n",
            "Epoch: 8, Loss:  0.5664313435554504\n",
            "Epoch: 9, Loss:  0.41700735688209534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl9THzVArVYX"
      },
      "source": [
        "#!pip install seqeval\n",
        "from seqeval.metrics import classification_report as classification_report_seqeval\n",
        "\n",
        "#print(classification_report_seqeval(truth_tags, pred_tags))\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    flat_preds = np.argmax(preds, axis=2).flatten()\n",
        "    flat_labels = labels.flatten()\n",
        "    return np.sum(flat_preds == flat_labels)/len(flat_labels)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JACOQXXrZks"
      },
      "source": [
        "def test_eval(model, testing_loader):\n",
        "    model.eval()\n",
        "    eval_loss = 0; eval_accuracy = 0\n",
        "    n_correct = 0; n_wrong = 0; total = 0\n",
        "    predictions , true_labels = [], []\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(dev, dtype = torch.long)\n",
        "            mask = data['mask'].to(dev, dtype = torch.long)\n",
        "            targets = data['tags'].to(dev, dtype = torch.long)\n",
        "\n",
        "            output = model(ids, mask, labels=targets)\n",
        "            loss, logits = output[:2]\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = targets.to('cpu').numpy()\n",
        "            predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "            true_labels.append(label_ids)\n",
        "            accuracy = flat_accuracy(logits, label_ids)\n",
        "            eval_loss += loss.mean().item()\n",
        "            eval_accuracy += accuracy\n",
        "            nb_eval_examples += ids.size(0)\n",
        "            nb_eval_steps += 1\n",
        "        eval_loss = eval_loss/nb_eval_steps\n",
        "        print(\"Validation loss: {}\".format(eval_loss))\n",
        "        print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "        pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
        "        valid_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
        "        print(classification_report_seqeval([valid_tags], [pred_tags]))\n",
        "    return (pred_tags, valid_tags)\n",
        "\n",
        "def train_eval(model, testing_loader):\n",
        "    model.eval()\n",
        "    eval_loss = 0; eval_accuracy = 0\n",
        "    n_correct = 0; n_wrong = 0; total = 0\n",
        "    predictions , true_labels = [], []\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(dev, dtype = torch.long)\n",
        "            mask = data['mask'].to(dev, dtype = torch.long)\n",
        "            targets = data['tags'].to(dev, dtype = torch.long)\n",
        "\n",
        "            output = model(ids, mask, labels=targets)\n",
        "            loss, logits = output[:2]\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = targets.to('cpu').numpy()\n",
        "            predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "            true_labels.append(label_ids)\n",
        "            accuracy = flat_accuracy(logits, label_ids)\n",
        "            eval_loss += loss.mean().item()\n",
        "            eval_accuracy += accuracy\n",
        "            nb_eval_examples += ids.size(0)\n",
        "            nb_eval_steps += 1\n",
        "        eval_loss = eval_loss/nb_eval_steps\n",
        "        print(\"Training loss: {}\".format(eval_loss))\n",
        "        print(\"Training Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "        pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
        "        valid_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
        "        print(classification_report_seqeval([valid_tags], [pred_tags]))\n",
        "    return (pred_tags, valid_tags)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwsiRbxcmPxN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "outputId": "899f8402-0f17-49f9-9826-32f415a39b26"
      },
      "source": [
        "preds,valids = train_eval(model, training_loader)\n",
        "print(\"Predicted Tag Counts\")\n",
        "print(pd.Series(preds).value_counts())\n",
        "print(\"True Counts\")\n",
        "print(pd.Series(valids).value_counts())\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
        "\n",
        "pd.Series(valids).value_counts().plot(kind='bar', title = 'True Values', ax=axes[0])\n",
        "pd.Series(preds).value_counts().plot(kind='bar', title = 'Predicted Values', ax=axes[1])\n",
        "\n",
        "confusion_matrix([x.split('-')[1] if x != 'O' else x for x in valids], [x.split('-')[1] if x != 'O' else x for x in preds], labels = ['PER', 'POS', 'ORG', 'O'])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.45788485805193585\n",
            "Training Accuracy: 0.9259895833333335\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ORG       0.01      0.01      0.01       143\n",
            "         PER       0.00      0.00      0.00        93\n",
            "         POS       0.06      0.01      0.02        71\n",
            "\n",
            "   micro avg       0.02      0.01      0.01       307\n",
            "   macro avg       0.02      0.01      0.01       307\n",
            "weighted avg       0.02      0.01      0.01       307\n",
            "\n",
            "Predicted Tag Counts\n",
            "O        16431\n",
            "I-ORG      706\n",
            "I-POS       41\n",
            "B-ORG       19\n",
            "I-PER        2\n",
            "B-POS        1\n",
            "dtype: int64\n",
            "True Counts\n",
            "O        16355\n",
            "I-ORG      311\n",
            "B-ORG      142\n",
            "I-POS      130\n",
            "I-PER       98\n",
            "B-PER       93\n",
            "B-POS       71\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    2,     0,    34,   155],\n",
              "       [    0,    20,     0,   181],\n",
              "       [    0,     1,   245,   207],\n",
              "       [    0,    21,   446, 15888]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3h3B-MJrcRk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "outputId": "4bc8b3e3-18d5-42e2-e8c8-5a95c96b1c80"
      },
      "source": [
        "# To get the results on the validation set. This data is not seen by the model\n",
        "\n",
        "preds, valids = test_eval(model, testing_loader)\n",
        "print(\"Predicted Tag Counts\")\n",
        "print(pd.Series(preds).value_counts())\n",
        "print(\"True Counts\")\n",
        "print(pd.Series(valids).value_counts())\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
        "\n",
        "pd.Series(valids).value_counts().plot(kind='bar', title = 'True Values', ax=axes[0])\n",
        "pd.Series(preds).value_counts().plot(kind='bar', title = 'Predicted Values', ax=axes[1])\n",
        "\n",
        "confusion_matrix([x.split('-')[1] if x != 'O' else x for x in valids], [x.split('-')[1] if x != 'O' else x for x in preds], labels = ['PER', 'POS', 'ORG', 'O'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 1.3873932361602783\n",
            "Validation Accuracy: 0.94703125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ORG       0.00      0.00      0.00        14\n",
            "         PER       0.00      0.00      0.00        16\n",
            "         POS       0.00      0.00      0.00        18\n",
            "\n",
            "   micro avg       0.00      0.00      0.00        48\n",
            "   macro avg       0.00      0.00      0.00        48\n",
            "weighted avg       0.00      0.00      0.00        48\n",
            "\n",
            "Predicted Tag Counts\n",
            "O        4339\n",
            "I-ORG      51\n",
            "I-POS      10\n",
            "dtype: int64\n",
            "True Counts\n",
            "O        4263\n",
            "I-ORG      35\n",
            "I-POS      32\n",
            "I-PER      22\n",
            "B-POS      18\n",
            "B-PER      16\n",
            "B-ORG      14\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    1,   37],\n",
              "       [   0,    1,    1,   48],\n",
              "       [   0,    0,    0,   49],\n",
              "       [   0,    9,   49, 4205]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eaj7E1iPo2L"
      },
      "source": [
        "Visualize Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PSJ2lVLKem8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d491ca-c2db-4d70-deaf-2dd284126765"
      },
      "source": [
        "!pip install sklearn_crfsuite"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.7/dist-packages (0.3.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (4.62.3)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.9.7)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn_crfsuite) (0.8.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvYH4hzwnrOR"
      },
      "source": [
        "# BERT-BASE-UNCASED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFfYMCr-LjxK"
      },
      "source": [
        "# Defining some key variables that will be used later on in the training\n",
        "\n",
        "MAX_LEN = max(slens)\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 2e-05\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWkl1KAULppJ"
      },
      "source": [
        "#ALL sentences to lower\n",
        "\n",
        "sentences = [s.lower() for s in sentences]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkYYqaU_LjxQ",
        "outputId": "8b7a102b-1064-40f2-a7fd-7761988e25c1"
      },
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "\n",
        "train_percent = 0.8\n",
        "train_size = int(train_percent*len(sentences))\n",
        "# train_dataset=df.sample(frac=train_size,random_state=200).reset_index(drop=True)\n",
        "# test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_sentences = sentences[0:train_size]\n",
        "train_labels = labels[0:train_size]\n",
        "\n",
        "test_sentences = sentences[train_size:]\n",
        "test_labels = labels[train_size:]\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(len(sentences)))\n",
        "print(\"TRAIN Dataset: {}\".format(len(train_sentences)))\n",
        "print(\"TEST Dataset: {}\".format(len(test_sentences)))\n",
        "\n",
        "training_set = CustomDataset(tokenizer, train_sentences, train_labels, MAX_LEN)\n",
        "testing_set = CustomDataset(tokenizer, test_sentences, test_labels, MAX_LEN)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: 108\n",
            "TRAIN Dataset: 86\n",
            "TEST Dataset: 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZicHE40LjxR"
      },
      "source": [
        "Create Dataloader for Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqLhR04-LjxS"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68BEAiRqLjxS",
        "outputId": "8baad9b1-a297-4463-87a7-814167ef49c8"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1490"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ySFLSg_LjxT"
      },
      "source": [
        "## Train\n",
        "\n",
        "### Create Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqLUFwzILjxU"
      },
      "source": [
        "class BERTUncasedClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERTUncasedClass, self).__init__()\n",
        "        self.l1 = transformers.BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=7)\n",
        "        # self.l2 = torch.nn.Dropout(0.3)\n",
        "        # self.l3 = torch.nn.Linear(768, 200)\n",
        "    \n",
        "    def forward(self, ids, mask, labels):\n",
        "        output_1= self.l1(ids, mask, labels = labels)\n",
        "        # output_2 = self.l2(output_1[0])\n",
        "        # output = self.l3(output_2)\n",
        "        return output_1"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaP18LRRLjxV",
        "outputId": "aa2f3867-8696-47e2-f53f-9e7bd8f17b9f"
      },
      "source": [
        "uncased_model = BERTUncasedClass()\n",
        "#model = BERT_CRF(tag2idx)\n",
        "uncased_model.to(dev)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTUncasedClass(\n",
              "  (l1): BertForTokenClassification(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wvfTU3pLjxV"
      },
      "source": [
        "optimizer = torch.optim.Adam(params =  uncased_model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2k27YZoLjxW"
      },
      "source": [
        "def train(epoch):\n",
        "    uncased_model.train()\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(dev, dtype = torch.long)\n",
        "        mask = data['mask'].to(dev, dtype = torch.long)\n",
        "        targets = data['tags'].to(dev, dtype = torch.long)\n",
        "\n",
        "        loss = uncased_model(ids, mask, labels = targets)[0]\n",
        "\n",
        "        # optimizer.zero_grad()\n",
        "        if _%500==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDRiZ-uYLjxW",
        "outputId": "404c701f-286c-474e-b7b9-6f9653f0a86f"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "for epoch in range(5):\n",
        "    train(epoch)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss:  1.8711979389190674\n",
            "Epoch: 1, Loss:  0.7893749475479126\n",
            "Epoch: 2, Loss:  0.7285884022712708\n",
            "Epoch: 3, Loss:  0.5398790836334229\n",
            "Epoch: 4, Loss:  0.4804110825061798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHj8rO8vLjxX"
      },
      "source": [
        "from seqeval.metrics import f1_score\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    flat_preds = np.argmax(preds, axis=2).flatten()\n",
        "    flat_labels = labels.flatten()\n",
        "    return np.sum(flat_preds == flat_labels)/len(flat_labels)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU6PDjJuOo69"
      },
      "source": [
        "def test_eval(model, testing_loader):\n",
        "    model.eval()\n",
        "    eval_loss = 0; eval_accuracy = 0\n",
        "    n_correct = 0; n_wrong = 0; total = 0\n",
        "    predictions , true_labels = [], []\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(dev, dtype = torch.long)\n",
        "            mask = data['mask'].to(dev, dtype = torch.long)\n",
        "            targets = data['tags'].to(dev, dtype = torch.long)\n",
        "\n",
        "            output = model(ids, mask, labels=targets)\n",
        "            loss, logits = output[:2]\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = targets.to('cpu').numpy()\n",
        "            predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "            true_labels.append(label_ids)\n",
        "            accuracy = flat_accuracy(logits, label_ids)\n",
        "            eval_loss += loss.mean().item()\n",
        "            eval_accuracy += accuracy\n",
        "            nb_eval_examples += ids.size(0)\n",
        "            nb_eval_steps += 1\n",
        "        eval_loss = eval_loss/nb_eval_steps\n",
        "        print(\"Validation loss: {}\".format(eval_loss))\n",
        "        print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "        pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
        "        valid_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
        "        #print(\"F1-Score: {}\".format(f1_score([pred_tags], [valid_tags])))\n",
        "        print(classification_report_seqeval([valid_tags], [pred_tags]))\n",
        "    return (pred_tags, valid_tags)\n",
        "\n",
        "def train_eval(model, testing_loader):\n",
        "    model.eval()\n",
        "    eval_loss = 0; eval_accuracy = 0\n",
        "    n_correct = 0; n_wrong = 0; total = 0\n",
        "    predictions , true_labels = [], []\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(dev, dtype = torch.long)\n",
        "            mask = data['mask'].to(dev, dtype = torch.long)\n",
        "            targets = data['tags'].to(dev, dtype = torch.long)\n",
        "\n",
        "            output = model(ids, mask, labels=targets)\n",
        "            loss, logits = output[:2]\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = targets.to('cpu').numpy()\n",
        "            predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "            true_labels.append(label_ids)\n",
        "            accuracy = flat_accuracy(logits, label_ids)\n",
        "            eval_loss += loss.mean().item()\n",
        "            eval_accuracy += accuracy\n",
        "            nb_eval_examples += ids.size(0)\n",
        "            nb_eval_steps += 1\n",
        "        eval_loss = eval_loss/nb_eval_steps\n",
        "        print(pd.Series(predictions).value_counts())\n",
        "        print(\"Training loss: {}\".format(eval_loss))\n",
        "        print(\"Training Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "        pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
        "        valid_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
        "        #print(\"F1-Score: {}\".format(f1_score([pred_tags], [valid_tags])))\n",
        "        print(classification_report_seqeval([valid_tags], [pred_tags]))\n",
        "    return (pred_tags, valid_tags)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EOSYO1kjTUNT",
        "outputId": "3df8ceb8-6a1d-4706-aca6-07791407ca54"
      },
      "source": [
        "preds, valids = train_eval(uncased_model, training_loader)\n",
        "print(\"Predicted Tag Counts\")\n",
        "print(pd.Series(preds).value_counts())\n",
        "print(\"True Counts\")\n",
        "print(pd.Series(valids).value_counts())\n",
        "\n",
        "\n",
        "\n",
        "#fig, axes = plt.subplots(nrows=1, ncols=2)\n",
        "\n",
        "pd.Series(valids).value_counts().plot(kind='bar', title = 'True Values', ax=axes[0])\n",
        "#pd.Series(preds).value_counts().plot(kind='bar', title = 'Predicted Values', ax=axes[1])\n",
        "\n",
        "confusion_matrix([x.split('-')[1] if x != 'O' else x for x in valids], [x.split('-')[1] if x != 'O' else x for x in preds], labels = ['PER', 'POS', 'ORG', 'O'])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...]    71\n",
            "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...]     1\n",
            "[6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...]     1\n",
            "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 6, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 6, 5, 5, 5, 5, ...]     1\n",
            "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...]     1\n",
            "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 6, 5, 5, 6, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, ...]     1\n",
            "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 5, 5, 5, 5, 5, 5, 6, 6, 6, 5, 5, 5, ...]     1\n",
            "[6, 6, 6, 6, 5, 5, 6, 6, 6, 5, 5, 5, 5, 6, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...]     1\n",
            "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...]     1\n",
            "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...]     1\n",
            "[6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...]     1\n",
            "[6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...]     1\n",
            "[5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 6, 5, 5, 5, 6, 5, 5, 5, 6, 5, 6, 5, 6, 6, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 6, 6, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...]     1\n",
            "[6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 6, 6, 6, 5, 6, 6, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 5, 5, 5, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, ...]     1\n",
            "[6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...]     1\n",
            "[6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...]     1\n",
            "dtype: int64\n",
            "Training loss: 0.6956270684798559\n",
            "Training Accuracy: 0.9265625000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ORG       0.00      0.00      0.00       143\n",
            "         PER       0.00      0.00      0.00        93\n",
            "         POS       0.00      0.00      0.00        71\n",
            "\n",
            "   micro avg       0.00      0.00      0.00       307\n",
            "   macro avg       0.00      0.00      0.00       307\n",
            "weighted avg       0.00      0.00      0.00       307\n",
            "\n",
            "Predicted Tag Counts\n",
            "O        16298\n",
            "I-ORG      902\n",
            "dtype: int64\n",
            "True Counts\n",
            "O        16355\n",
            "I-ORG      311\n",
            "B-ORG      142\n",
            "I-POS      130\n",
            "I-PER       98\n",
            "B-PER       93\n",
            "B-POS       71\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,    37,   154],\n",
              "       [    0,     0,     3,   198],\n",
              "       [    0,     0,   248,   205],\n",
              "       [    0,     0,   614, 15741]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(valids).value_counts().plot(kind='bar', title = 'Train Data Labels')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "MX4I7LgFW9Bo",
        "outputId": "4497f27c-cbca-4a45-c064-53ef629e1fff"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f50145b2a90>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        },
        "id": "IqJWeEN0Oo6-",
        "outputId": "3157ce4f-31d1-4bfb-df89-6d0824bae5e6"
      },
      "source": [
        "# To get the results on the validation set. This data is not seen by the model\n",
        "from seqeval.metrics import classification_report as classification_report_seqeval\n",
        "\n",
        "preds, valids = test_eval(uncased_model, testing_loader)\n",
        "print(\"Predicted Tag Counts\")\n",
        "print(pd.Series(preds).value_counts())\n",
        "print(\"True Counts\")\n",
        "print(pd.Series(valids).value_counts())\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
        "\n",
        "pd.Series(valids).value_counts().plot(kind='bar', title = 'True Values', ax=axes[0])\n",
        "pd.Series(preds).value_counts().plot(kind='bar', title = 'Predicted Values', ax=axes[1])\n",
        "\n",
        "confusion_matrix([x.split('-')[1] if x != 'O' else x for x in valids], [x.split('-')[1] if x != 'O' else x for x in preds], labels = ['PER', 'POS', 'ORG', 'O'])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 1.614353358745575\n",
            "Validation Accuracy: 0.95859375\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ORG       0.00      0.00      0.00        14\n",
            "         PER       0.00      0.00      0.00        16\n",
            "         POS       0.00      0.00      0.00        18\n",
            "\n",
            "   micro avg       0.00      0.00      0.00        48\n",
            "   macro avg       0.00      0.00      0.00        48\n",
            "weighted avg       0.00      0.00      0.00        48\n",
            "\n",
            "Predicted Tag Counts\n",
            "O        4373\n",
            "I-ORG      27\n",
            "dtype: int64\n",
            "True Counts\n",
            "O        4263\n",
            "I-ORG      35\n",
            "I-POS      32\n",
            "I-PER      22\n",
            "B-POS      18\n",
            "B-PER      16\n",
            "B-ORG      14\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,   38],\n",
              "       [   0,    0,    2,   48],\n",
              "       [   0,    0,    1,   48],\n",
              "       [   0,    0,   24, 4239]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk_K3zjLjxZ"
      },
      "source": [
        "### Test Eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVCHjPhel4Kc"
      },
      "source": [
        "# Sources \n",
        "\n",
        "J. Hockenmaier, 2018. CS447: Natural Language Processing. *University of Illinois.* https://courses.engr.illinois.edu/cs447/fa2018/Slides/Lecture06.pdf\n",
        "\n",
        "\n",
        "Data:\n",
        "Leon Derczynski, Eric Nichols, Marieke van Erp, Nut Limsopatham; 2017. **Results of the WNUT2017 Shared Task on Novel and Emerging Entity Recognition**. In *Proceedings of the Workshop on Noisy, User-generated Text*, at EMNLP. https://github.com/leondz/emerging_entities_17"
      ]
    }
  ]
}