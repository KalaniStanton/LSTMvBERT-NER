{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywBHRmr7q25Y"
      },
      "source": [
        "# Bi-LSTM-CRF \n",
        "\n",
        "The following notebook contains code and instructions for transforming custom-labeled data (using Doccano) \n",
        "\n",
        "Built from code available here: https://github.com/PythonWorkshop/intro-to-nlp-with-pytorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUMXsZ7_caLi",
        "outputId": "1f192fbd-9ec5-43ba-a1ac-f52171207905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vHzHqMC6xZPt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd85c306-0696-4801-e469-a10e62224dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install seqeval\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na22g0B5xaSg"
      },
      "source": [
        "## LSTM Networks\n",
        "\n",
        "There is an LSTM cell for each $x_t$ in the input vector, and there are hidden states $h_t$ that are either passed into the output layer or are transferred into the cell on the right. There is also a cell state $C_t$, which is updated using gates that are composed of activation functions ($\\sigma, \\tanh$) and matrix operations that are applied to the tensors in the LSTM network.\n",
        "\n",
        "### The activation functions\n",
        "\n",
        "- Sigmoid $\\sigma$\n",
        "    - Squishes values between 0 and 1, with an S shape\n",
        "- $\\tanh$\n",
        "    - Squishes values between -1 and 1, with an S shape\n",
        "\n",
        "### The gates\n",
        "\n",
        "Used to pass information to adjust the cell-state of the LSTM\n",
        "\n",
        "- *Forget Gate*\n",
        "    - Decides what information that you want the network to forget. Remove that from the cell-state. Uses sigmoid Layer\n",
        "    - Takes in previous hidden state and removes current state of target values likelihood.\n",
        "\n",
        "$$\n",
        "f_t = \\sigma(W_f [h_{t-1}, x_t] + b_f)\n",
        "$$\n",
        "\n",
        "- *Input Gate*\n",
        "    - Decides what information should be stored in the cell state (what information is important), decide what to update with a sigmoid $\\sigma$ layer ($i_t$), and creates candidate values for the cell state using $\\tanh$ layer ($\\tilde{C}_t$)\n",
        "    - This gate will replace previous likelihood for target value with likelihood of not being the target value.\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "i_t &= \\sigma(W_f [h_{t-1}, x_t] + b_f) \\\\\n",
        "\\tilde{C}_t &= \\tanh(W_C [h_{t-1}, x_t] + b_C)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "**Update Cell State**\n",
        "\n",
        "Following the aformentioned gates, updates to the cell state occur using multiplication of $f_t * C_{t-1}$ and the additions of new candidate values, scaled by their importance $(i_t * \\tilde{C}_t)$ to the cell state.\n",
        "\n",
        "$$\n",
        "C_t = f_t * C_{t-1} + i_t * \\tilde{C}_t\n",
        "$$\n",
        "\n",
        "- *Output Gate*\n",
        "    - returns a filtered version of the cell state by multiplying the matrix from the sigmoid function $o_t$ with the $\\tanh$ applied to the cell state $C_t$.\n",
        "    - This gate tracks the magnitude of previous states and how they apply to the prediction of our target state.\n",
        "    - The resulting hidden state $h_t$ can be split to return the prediction at that time step, or pass that to a later timestep for another LSTM\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "o_t &= \\sigma(W_o [h_{t-1}, x_t] + b_o) \\\\\n",
        "h_t &= o_t * \\tanh(C_t)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "### Input and Dimensions\n",
        "\n",
        "We need to be able to map our words and our labels to a dictionary of integer values for computing within the neural net.\n",
        "\n",
        "### Loss Function\n",
        "\n",
        "Negative Log Likelihood is often used. NLL identifies the smallest $-\\log(P(word))$\n",
        "\n",
        "## Bidirectional LSTM Networks\n",
        "\n",
        "https://www.youtube.com/watch?v=5rZvUpd-4Kk\n",
        "\n",
        "https://github.com/PythonWorkshop/intro-to-nlp-with-pytorch/blob/master/Named_Entity_Recognition/NamedEntityRecognition.ipynb\n",
        "\n",
        "https://github.com/jidasheng/bi-lstm-crf/blob/master/bi_lstm_crf/model/crf.py\n",
        "\n",
        "https://paperswithcode.com/paper/bidirectional-lstm-crf-models-for-sequence/review/\n",
        "\n",
        "https://arxiv.org/pdf/1508.01991.pdf\n",
        "\n",
        "Each word becomes a word embedding, and each sentence is a training point. Word embedding enters the cell of a nonlinear LSTM layer. In a bidirectional LSTM, the data are trained forwards on the first set of LSTM and backwards on a second set of LSTMs. Ultimately, these two LSTM layers give us bi-directional context that help us understand the boundaries of entities.\n",
        "\n",
        "Why Bi-directional?\n",
        "- Unidirectional LSTM can only account for context from the past; thus, the $h_t$ hidden state takes only past information as input.\n",
        "\n",
        "This bi-directionality is especially useful for chunking and tagging because it can \n",
        "\n",
        "Ultimately, the forward and backward LSTMs produce two hidden states, then we concatenate those vectors and apply the big vector to the *conditional random field*. \n",
        "\n",
        "Note: LSTM addresses the vanishing gradient problem with cell state and non linear activation function layers.\n",
        "\n",
        "## Decoder\n",
        "\n",
        "Aside from the contextual power of the LSTM, the BiLSTM-CRF architecture is powerful because of the decoder (Viterbi) that uses a conditional random field to map the probability of transitioning from a tag of each type to a tage of any other type at the next time step. The decoding occurs by finding paths through \n",
        "\n",
        "### Conditional Random Field\n",
        "\n",
        "A conditional random field consists of a transition matrix, \"the costs of transitioning from a tag to another tag\", wherein we use a scheme for labeling the relative position of words in a single named entity. One common application is the *B-I-O* (beginning-inner-outer).\n",
        "\n",
        "Each data-point will give you a transition matrix like B to I or I to O or O to O. There are somethings that are less likely to happen, like an O to I. \n",
        "\n",
        "The Conditional Random Field is based upon a matrix of parameters, $V$, wherein the length of each row (number of columns) is equal to the tag set space, and the rows represent each of the words (features) in the sentence (sequence)\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "P(x|y) &= \\frac{1}{Z(x)}\\exp(\\sum^M_{j=1}(A_{y^t,y^{t-1}}+ O_{y^t,x^t}))\n",
        "\\\\\n",
        "\\\\\n",
        "Z(x) &= \\sum_{y'}\\exp\\{F(y', x)\\}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "^This is a first order sequential logistic regression.\n",
        "\n",
        "### Viterbi Algorithm\n",
        "\n",
        "Prediction is using the $P(x|y)$ to find the most likely argument; i.e.\n",
        "\n",
        "$$\n",
        "\\text{argmax}_{y}\\sum^M_{j=1}(A_{y^t,y^{t-1}}+ O_{y^t,x^t})\n",
        "$$\n",
        "\n",
        "The conditional random field and viterbi algorithm take the concatenated vector of hidden states and decodes them. These give us a likely sequence through each data point (sentence); this is what the Bi-LSTM-crf for Named Entity Recognition does.\n",
        "\n",
        "So, if we have a bunch of transition matrices, i.e. possible paths through a sentence with different sequences of those tags. The viterbi algorithm finds the most likely path. It finds this \"survivor path\" based on a cost function that eliminates paths that have higher edge weights between connections.\n",
        "\n",
        "In the code: There is a viterbi decoder (decodes the transition matrix values), a cost function, and returns a probability with the path.\n",
        "\n",
        "The final value that the cost function evalueates is the sum of the corresponding values from the transition matrices and the LSTM output features mapped onto the tag space.\n",
        "\n",
        "## Bi-LSTM Structural Outline\n",
        "\n",
        "- Word Embeddings\n",
        "- Forward LSTM (w/ hidden in/out)\n",
        "- Backwards LSTM (w/ hidden in/out)\n",
        "- Output Layer (Linear Layer from hidden to tagset size)\n",
        "- CRF layer (Transition matrix and Viterbi Algorithm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JYeja6oJECbT",
        "outputId": "a7bd66eb-78f7-455a-a23a-0cce0ba92e37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbxud-ymEJUN",
        "outputId": "4421b3b2-be24-4288-bc26-0371916f8f98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa91e75e9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Imports for this tutorial\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import json\n",
        "from collections import defaultdict, OrderedDict\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYfoSkauEOWE",
        "outputId": "88347aed-dd7c-4f41-a756-541579fa3a7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNTXbBKsEqth"
      },
      "source": [
        "Set helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yuuAlt8AEaVZ"
      },
      "outputs": [],
      "source": [
        "def argmax(vec):\n",
        "    \"\"\"Return the maximum argument as a\"\"\"\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        seq - the sequence (array)\n",
        "        to_ix - the indices to which seqence values are converted (dict)\n",
        "\n",
        "    Output:\n",
        "        Numerical tensor\n",
        "        \"\"\"\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "def log_sum_exp(vec):\n",
        "    \"\"\"Compute log sum exp in a numerically stable way for \n",
        "    the forward algorithm\"\"\"\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UWhZubSK2FO"
      },
      "source": [
        "Use Docano to label the data\n",
        "\n",
        "Install Postgres and Doccano\n",
        "\n",
        "Code for Porting from Doccano to format for the BI-LSTM-CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj3ebBppKy6H",
        "outputId": "985e2fcf-3809-4661-9590-8c527643ab56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 11195, 'data': 'DAMON CARSON J.D.', 'label': [[0, 6, 'B-PER'], [6, 13, 'I-PER'], [13, 17, 'B-POS']]}\n",
            "108\n"
          ]
        }
      ],
      "source": [
        "# Read export file\n",
        "with open('/content/drive/MyDrive/ML_Models/Bi-LSTM/doccano_output.jsonl', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "print(json.loads(lines[40]))\n",
        "print(len(lines))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EHgczL1YL1pR"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# The numerical doccano label to actual label (B-I-O scheme)\n",
        "\n",
        "ix_to_label = {8: 'O', 7: 'I-ORG', 6:'B-ORG', 5:'I-POS', 4:'B-POS', 3: 'I-PER', 2: 'B-PER'}\n",
        "    \n",
        "# train/test data\n",
        "data = []\n",
        "\n",
        "# Vocabulary\n",
        "vocab = set()\n",
        "    \n",
        "# Loop over each data point (a corpus of labeled text) to extract words\n",
        "for line in lines:\n",
        "    # An ordered dict will keep items in order for further manipulation\n",
        "    # so we initialize here\n",
        "    orddict = OrderedDict({})\n",
        "    # Lists to hold the words and labels\n",
        "    words = []\n",
        "    labels = []\n",
        "    # Convert line to json\n",
        "    input_json = json.loads(line)\n",
        "    annots = input_json['label']\n",
        "    text = input_json['data']\n",
        "    \n",
        "    # Add each word annotation to OrderedDict\n",
        "    for ann in annots:\n",
        "        orddict[ann[0]] = ann\n",
        "    \n",
        "    # Sort ordered dict because there's no guarantee reading json\n",
        "    # maintained order\n",
        "    orddict = sorted(orddict.items(), key=lambda x: x[1][0])\n",
        "    \n",
        "    for item in orddict:\n",
        "        # the item is a tuple where second value is the actual value we want\n",
        "        ann = item[1]\n",
        "        # Subset text string\n",
        "        word = text[ann[0]:(ann[1])].rstrip()\n",
        "        label = ann[2]\n",
        "        # Add to list for this datum/corpus\n",
        "        words.append(word)\n",
        "        labels.append(label)\n",
        "        vocab.add(word)\n",
        "    # Add to overall data containers\n",
        "    data.append((words, labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T18Ls2tms1f",
        "outputId": "7da501bc-a577-46c7-ca0a-27e9cee35fff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1490"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-DH8mklL7AP"
      },
      "source": [
        "Split Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fvhm2cptL44b",
        "outputId": "f8ac4652-8cca-4808-f1f4-a164494d245c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "random.shuffle(data)\n",
        "num_train = math.floor(len(data) * 0.8) # 80% to train\n",
        "training_data, test_data = data[:num_train], data[num_train:]\n",
        "len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxerfqWXw3B1",
        "outputId": "9ea59309-2af6-42c9-dd12-34c5f2d5f18a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1490"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XwP0bgQGlN6"
      },
      "source": [
        "## Train\n",
        "\n",
        "### Create Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3nQfPHzWMnws"
      },
      "outputs": [],
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, mini_batch):\n",
        "        \"\"\"Initialize network.\"\"\"\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.mini_batch = mini_batch\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim) # Create word embedding layer (linear layer)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=1, #Split our hidden dimension because it's creating two sets of LSTM cells\n",
        "                            bidirectional=True) \n",
        "\n",
        "        # Creates feature vectors from the concatenated hidden states output from the LSTM layers\n",
        "        # Turns it into a format that CRF can use\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Initialize matrix of randomized transition values and add it to our model with nn.Parameter \n",
        "        self.transitions = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # Enforce constraints on the transition matrix if the sequence...\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000 # stops at a start tag\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000 # starts at a stop tag\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        \"\"\"Two tensors to hold hidden states, one for each\n",
        "        LSTM direction with dimensions of \n",
        "        (num_layers, minibatch, hidden_dim)\"\"\"\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "    \n",
        "    def _forward_alg(self, feats):\n",
        "        \"\"\"Forward pass of our training algorithm. \n",
        "        The central process of the CRF.\n",
        "\n",
        "        Input:\n",
        "            The word embeddeding vectors for a sentence\n",
        "\n",
        "        Iterates through features and through the tag set space. \n",
        "        Evaluates the cost of transitioning to each tag in the tag space.\n",
        "        This gives us new tranistion matrix values and returns a loss via log_sum_exp\"\"\"\n",
        "        # Compute partition function for \n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG (\"<START>\") has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            # Iterate through the tag_set space\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # emit_score: \"Emission Score\" p(w_i|t_i)\n",
        "                emit_score = feat[next_tag].view(1, -1).expand(1, self.tagset_size)\n",
        "                # tans_score: \"Transition Score\" P(t_i | t_i-1)\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # next_tag_var: Edge values connecting feature with subsequent tag\n",
        "                # edge (i -> next_tag)\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # alpha_t contains the log-sum-exp of all the scores for each feature and it's edges.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            # concatenate the alphas_t into a vector\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "\n",
        "\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha # RETURNS THE LOSS\n",
        "    \n",
        "    def _get_lstm_features(self, sentence):\n",
        "        \"\"\"Compute output vector of BiLSTM - used in \n",
        "        the forward pass of network\n",
        "        \n",
        "        This returns the feature vector with the shape that the CRF requires\"\"\"\n",
        "        self.hidden = self.init_hidden() #take hidden states\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1) # Reshape word embeddings to len of sentence\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden) # run those word embeddings through an lstm\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim) # return feature vectors to reshape into shape (len(sentence), hidden_dim)\n",
        "        # Map LSTM features into tag space\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        \"\"\"Gives the score of a provided tag sequence\n",
        "        \n",
        "        Inputs:\n",
        "            feats: feature output from _get_lstm_features(sentence)\n",
        "            tags: the tags for NER\n",
        "        \"\"\"\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]] #accumulate score of transitions_MATRIX[next_tag, current tag] + score of next feature[tag]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        \"\"\"This is used when we are scoring and doing inference (after training)\n",
        "\n",
        "        We take the maximum transition value (most likely transition) over the previous states.\n",
        "\n",
        "        Input:\n",
        "            loglikelihoods: torch tensor.\n",
        "\n",
        "        Output:\n",
        "            tuple: (loglikelihood(sequence), sequence). The first entry is the loglikelihood of this sequence. The second is the most likely sequence of labels. \n",
        "        \"\"\"\n",
        "        backpointers = [] # will store the transition values\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats: #for each word in sequence\n",
        "            backptrs_t = []  # holds the backpointers\n",
        "            viterbivars_t = []  # holds the viterbi variables\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i]: the sum of the viterbi variable for tag `i` at the previous step `t` and the score of transitioning from tag i to next_tag.\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                # Store the maximum score from this sum and append the id to list of backpointers\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                backptrs_t.append(best_tag_id)\n",
        "                # Append the value associated with best_tag_id\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Add emission scores, and use forward_var to store the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1).to(device)\n",
        "            backpointers.append(backptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG to complete path\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        # Store path scores\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for backpointers_t in reversed(backpointers):\n",
        "            best_tag_id = backpointers_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        \"\"\"Calculate the negative log likelihood given a sequence and labels.\n",
        "        This is used in training because the score output is used for the loss\"\"\"\n",
        "        # Get output of Bi-LSTM\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        # Do forward pass through network to get score for training attempted path\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        # The score we get from the pre-labeled path\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        \"\"\"The forward pass function for training the network.\n",
        "        This is used in inference only.\"\"\"\n",
        "        # Get the emission scores (output layer) from the \n",
        "        # BiLSTM \n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "O7grQ3opMGA-"
      },
      "outputs": [],
      "source": [
        "# Hyper-Parameters for the model\n",
        "EMBEDDING_DIM = len(vocab) # Non-specific embedding dimension parameter, but is normally = to length of vocabulary.\n",
        "HIDDEN_DIM = 6 # Hidden dimensions detemines shape of the LSTM output.\n",
        "MINIBATCH_SIZE = 1\n",
        "LEARNING_RATE = 5e-2 # 0.05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54y_wrv5sWND"
      },
      "source": [
        "Pre Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IaN2C8I98AFU"
      },
      "outputs": [],
      "source": [
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "\n",
        "# Create a lookup dict for all possible words and record their index\n",
        "word_to_ix = {k: v for (k, v) in zip(vocab, range(len(vocab)))}\n",
        "tag_to_ix = {\"B-PER\": 0, \"I-PER\": 1, \"B-POS\":2, \"I-POS\":3, \"B-ORG\":4, \"I-ORG\": 5, \"O\": 6, START_TAG: 7, STOP_TAG: 8}\n",
        "ix_to_tag = {0: \"B-PER\", 1: \"I-PER\", 2:\"B-POS\", 3:\"I-POS\", 4: \"B-ORG\", 5:\"I-ORG\", 6: \"O\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wj9lJ7ek8Ead"
      },
      "outputs": [],
      "source": [
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, 16)\n",
        "model = model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz8E_MfXsXkv",
        "outputId": "26300909-92a0-4961-e4a8-15840329f12f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:    ['I-PER', 'I-POS', 'I-PER', 'I-POS', 'I-PER', 'B-PER', 'B-POS', 'B-PER']\n",
            "Ground truth:  ['B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG']\n",
            "['Society', 'for', 'Advancement', 'of', 'Chicanos', 'and', 'Native', 'Americans'] \n",
            " 8\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    precheck_sent = prepare_sequence(training_data[1][0], word_to_ix)\n",
        "    precheck_sent = precheck_sent.to(device)\n",
        "    pred =  model(precheck_sent)[1]\n",
        "    print('Prediction:   ', [ix_to_tag[idx] for idx in pred])\n",
        "    print('Ground truth: ', training_data[1][1])\n",
        "    print(training_data[1][0], \"\\n\", len(training_data[1][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYVM1xF8sh9Q"
      },
      "source": [
        "Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI1-xQDXCkFz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy1tMLcpshj_",
        "outputId": "29252461-a77f-4855-c7d3-fc7b5b615f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 Loss: 14.604023560535076\n",
            "Epoch: 20 Loss: 13.05058504183625\n",
            "Epoch: 30 Loss: 12.736434719405432\n"
          ]
        }
      ],
      "source": [
        "losses = []\n",
        "for epoch in range(30):  \n",
        "    for sentence, tags in training_data:\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance of LSTM\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
        "        sentence_in, targets = sentence_in.to(device), targets.to(device)\n",
        "\n",
        "        # Step 3. A lot happens.  Run our forward pass to get features from BLSTM,\n",
        "        # run the CRF and get the negative log likelihoods and find the best \n",
        "        # \"path\" through sentence with the tags using the viterbi algorithm \n",
        "        # (also part of forward pass).\n",
        "        # BTW our dynamic computational graph is created with the forward pass\n",
        "        # Returns the forward score - ground truth score (our loss measure)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "\n",
        "        # Step 4. Compute the loss, gradient, backprop, and update the \n",
        "        # parameters by calling optimizer.step() - optimizer here is \n",
        "        # SGD for our CRF\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(\"Epoch: {} Loss: {}\".format(epoch+1, np.mean(losses)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "94h8QKegD5cq"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "torch.save(model.state_dict(), 'drive/MyDrive/ML_Models/Bi-LSTM/model_2.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uckej3Ejet4L"
      },
      "source": [
        "### Training Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYCniL0h5VPv",
        "outputId": "aefc2ffb-1158-4d0f-8177-8b6a5f986123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 10.5319%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ORG       0.35      0.13      0.19       106\n",
            "         PER       0.38      0.24      0.30        78\n",
            "         POS       0.00      0.00      0.00        71\n",
            "\n",
            "   micro avg       0.29      0.13      0.18       255\n",
            "   macro avg       0.24      0.13      0.16       255\n",
            "weighted avg       0.26      0.13      0.17       255\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  2003,   1607,    635,   2524],\n",
              "       [   857,   3027,    301,   3281],\n",
              "       [   818,   3320,   2940,   5354],\n",
              "       [   727,   1864,   1582, 101434]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "from seqeval.metrics import classification_report as classification_report_seqeval\n",
        "model.eval() #changes the functional state of batch norm and dropout layers\n",
        "pred_tags = []\n",
        "truth_tags = []\n",
        "pred_list = []\n",
        "true_list = []\n",
        "\n",
        "for i in range(len(training_data)):\n",
        "    with torch.no_grad():\n",
        "        precheck_sent = prepare_sequence(training_data[i][0], word_to_ix)\n",
        "        precheck_sent = precheck_sent.to(device)\n",
        "        pred =  model(precheck_sent)[1]\n",
        "        pred_tags.append([ix_to_tag[idx] for idx in pred])\n",
        "        #print('Prediction:   ', [ix_to_tag[idx] for idx in pred])\n",
        "        #print('Ground truth: ', training_data[i][1])\n",
        "        truth_tags.append(training_data[i][1])\n",
        "        #print(training_data[i][0])\n",
        "        pred_list.extend(pred_tags)\n",
        "        true_list.extend(truth_tags)\n",
        "\n",
        "correct = sum([pred_list[i] == true_list[i] for i in range(len(true_list))])\n",
        "print(\"Training Accuracy: \" + str(round(correct/len(pred_list)*100, 4)) + \"%\")\n",
        "print(classification_report_seqeval(truth_tags, pred_tags))\n",
        "\n",
        "confusion_matrix([x_i.split('-')[1] if x_i != 'O' else x_i for x in true_list for x_i in x], [x_i.split('-')[1] if x_i != 'O' else x_i for x in pred_list for x_i in x], labels = ['PER', 'POS', 'ORG', 'O'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKxlzm4hR77S"
      },
      "source": [
        "### Test Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3rItLD1eWRu",
        "outputId": "df6e13e2-8c8b-4ff5-cf76-7b60062666df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 11.0672%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ORG       0.10      0.02      0.03        51\n",
            "         PER       0.33      0.16      0.22        31\n",
            "         POS       0.00      0.00      0.00        18\n",
            "\n",
            "   micro avg       0.16      0.06      0.09       100\n",
            "   macro avg       0.14      0.06      0.08       100\n",
            "weighted avg       0.15      0.06      0.08       100\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 149,  203,   70,  309],\n",
              "       [  14,  185,   59,  267],\n",
              "       [ 114,  913,  116, 1179],\n",
              "       [  42,  503,   59, 1704]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "from seqeval.metrics import classification_report as classification_report_seqeval\n",
        "model.eval() #changes the functional state of batch norm and dropout layers\n",
        "pred_tags = []\n",
        "truth_tags = []\n",
        "pred_list = []\n",
        "true_list = []\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "    with torch.no_grad():\n",
        "        precheck_sent = prepare_sequence(test_data[i][0], word_to_ix)\n",
        "        precheck_sent = precheck_sent.to(device)\n",
        "        pred =  model(precheck_sent)[1]\n",
        "        pred_tags.append([ix_to_tag[idx] for idx in pred])\n",
        "        #print('Prediction:   ', [ix_to_tag[idx] for idx in pred])\n",
        "        #print('Ground truth: ', test_data[i][1])\n",
        "        truth_tags.append(test_data[i][1])\n",
        "        #print(test_data[i][0])\n",
        "        pred_list.extend(pred_tags)\n",
        "        true_list.extend(truth_tags)\n",
        "\n",
        "correct = sum([pred_list[i] == true_list[i] for i in range(len(true_list))])\n",
        "print(\"Validation Accuracy: \" + str(round(correct/len(pred_list)*100, 4)) + \"%\")\n",
        "print(classification_report_seqeval(truth_tags, pred_tags))\n",
        "confusion_matrix([x_i.split('-')[1] if x_i != 'O' else x_i for x in true_list for x_i in x], [x_i.split('-')[1] if x_i != 'O' else x_i for x in pred_list for x_i in x], labels = ['PER', 'POS', 'ORG', 'O'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "RDUjcwczysb2",
        "outputId": "3596d6b3-e983-4a98-b7b5-4b698805373f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa8d1325c90>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEVCAYAAAAM3jVmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdY0lEQVR4nO3de7hV1Xnv8e+voGg0CViQGi7iBfWgJ6JSNU2kHk0VSRo0PTXsYyOIDdpiq09ymqg952g15Niq9RyfRlKsRO2j7Gg1kSfBKrG56GmIoqF4JWwVBYKIYrxGE/A9f8yxdLLYm31ft/H7PM969pxjXtaY8M53zTXmWGMqIjAzszz8Vr0rYGZmteOkb2aWESd9M7OMOOmbmWXESd/MLCNO+mZmGXHSz5Ck4yWtr/W21pok3Sjpq2n6OEmra/S+IenAAd7ne8dSy21ryUl/AEh6o/R6V9KvSvNnDOL7zpb0wGDt31qHpLWluNyUEtSeA/0+EXF/RBzcg/oMauxK+qGkPx2s/TczJ/0BEBF7Vl7A88AflspuqawnaWj9amlWxCVwJDAF+B/VKzhGW5+T/iCqNIVI+oqkF4BvdnaFU/6aKmmYpKskPZ+uyL4hafc+vPdZkp6U9LqkZySd08k6F0t6KV0FnlEq73Ed0rFtSO+zWtKJva2r1VZEbADuBg6D9+JvnqQ1wJpU9mlJKyX9UtK/S/poZXtJR0h6JP2ffwvYrbRsu+Y/SeMk3Slps6SXJf2DpP8EfAP4WPrm8cu07k7jTtJfSdoo6ReS5vT1+CXdLukFSa9K+rGkQ6tWGSlpWTq+H0nat7TtIWnZlhTvp3fxHiMlfTf9+22RdL+khsi3DVGJFvc7wF7AvsDcHqx/BXAQMBk4EBgD/K8+vO+LwKeBDwFnAddIOrKqXiPT/mcBCyVVvpb3qA5p/fOA342IDwInA2v7UFerIUnjgOnAz0rFpwLHAJMkHQEsAs4Bfhv4R2BJSsq7At8B/pkirm8H/qiL9xkCfBd4DphAEUftEfEkcC7wk/RteHjapMu4kzQN+O/AHwATgU/245/g7rSPvYFHgFuqlp8BXE5xfqysLJe0B7AMuDVtOxO4TtKkTt7jS8B6YBQwGrgYaIwxbyLCrwF8USS9T6bp44FfA7uVls8GHqjaJiiCXMCbwAGlZR8Dnu3ivXbY107q9R3g/FK9tgJ7lJbfBvzP7uqQtl2fpg+k+HD5JLBLvf/t/eo2Lt8AfkmRhK8Ddo/34++E0roLgMurtl8N/D4wFfgFoNKyfwe+2kl8fAzYDAztpD7bxW4P4m4RcEVp2UGV86aL4/0h8Kc9+HcZnvbz4TR/I8UHU2X5nsA2YBzwOeD+qu3/EbiktG3l3+Ey4K6u6lfPl9vvBt/miHi7h+uOAj4APCypUiZgSG/fVNIpwCUUJ8dvpf0+WlrllYh4szT/HPCR3tQhIjokXQBcChwq6R7gixHxi97W12ri1Ij4fhfL1pWm9wVmSfqLUtmuFPERwIZImS15rot9jgOei4itPahbd3H3EeDhHrznTqVvH/OBP07v+W5aNBJ4NU2/928REW9I2pLef1/gmEpzVDKU4ltPtSspzot70/EsjIgr+lLngebmncFX/ZXuTYrgBkDS75SWvQT8Cjg0Ioan14ejuPnWY5KGAXcAVwGjo/j6vJTiJKoYkb6uVoynuILrVR0i4taI+ATFCRHA3/amrtYwynG6Dphf+v8fHhEfiIjFwEZgjEqZmSJ2OrMOGN/FzeHq86K7uNtI8SHS3Xt2578BMyi+nX6YotkJtj833nuf1MNpL4pzYx3wo6p/lz0j4s92OLiI1yPiSxGxP/AZ4IuNcr/LSb/2/oPiqniypN0orgYAiIh3gesp2t/3BpA0RtLJO9mfJO1WflFclQ2j+Gq9NV31n9TJtn8jaVdJx1G0/9/emzpIOljSCelD5m2Kk/bd6vWs6VwPnCvpGBX2kPQpSR8EfkLRNPiXknaR9Fng6C728yBFsr4i7WM3SR9PyzYBY9M9gp7E/m3AbEmTJH2A4ltsd4ZWnRu7AB8E3gFeprj4+lon202X9IlUt8uB5RGxjuL+xEGSPp+OfRdJv5tuTG9HxY3wA9OH46sUTUQNcW446ddYRPycor3v+xQ9Jar7Kn8F6ACWS3otrbezfs+/R5Fsq19/SXGivEJxdbOkarsX0rJfUNyoOjcinuplHYZR3Hx7Ke1vb+CindTVmkBErAC+APwDRYx0ULTBExG/Bj6b5rdQtHPf2cV+tgF/SHHv53mKG5ufS4v/DXgceEHSS6msy7iLiLuB/5O260h/u7OA7c+JbwI3UzQNbQCeAJZ3st2tFB8qW4CjgD9JdXid4uJpJsV58wLFN9thnexjYqr/GxQflNdFxA96UOdBp+2b5szMrJX5St/MLCNO+mZmGXHSNzPLiJO+mVlGnPTNzDLS0L/IHTlyZEyYMKHe1bAW9vDDD78UEaNq/b6ObRtMO4vrhk76EyZMYMWKFfWuhrUwSX36OX9/ObZtMO0srt28Y2aWESd9M7OMOOmbmWXESd+yNWfOHIDDJT1WKZP0LRVPjFqp4oliK1P5BBXPmK0s+0Zpm6MkPSqpQ9K1VSNQmjUUJ33L1uzZsyE9HrAiIj4XEZMjYjLF8NTlwcSeriyLiHNL5QsoBiibmF7TBrXiZv3gpG/Zmjp1KhTDBO8gXa2fDize2T4k7QN8KCKWpweL3Ezx6EGzhuSkb9a544BNEVH+JrCfpJ+lh2Ufl8rGUAwZXLE+lZk1pIbup29WR21sf5W/ERgfES9LOgr4jqRDe7NDSXOBuQDjx/f1wU9m/dNySX/Chd8b9PdYe8WnBv09rH7S4/0+S/EADQAi4h2KJy4REQ9Lepri+cMbgLGlzcemsh1ExEJgIcCUKVP8IIsWUIt8AwObc9y8Y7ajTwJPRcR7zTaSRqWHaiNpf4obts9ExEbgNUnHpvsAZwJ31aPSZj3hpG/ZamtrAzgEOFjSeklnp0Uz2fEG7lRgVerC+S8Uj5fckpb9OfBPFI/xexq4e7DrbtZXLde8Y9ZTixcvpr29fVVETCmXR8Ts6nUj4g6KLpw7SM+UPWxQKmk2wHylb2aWESd9M7OMOOmbmWXESd/MLCNO+mZmGXHSNzPLiJO+mVlGnPTNzDLipG9mlhEnfTOzjDjpm5llxEnfzCwjTvpmZhlx0jczy4iTvplZRpz0zcwy4qRvZpYRJ30zs4w46ZuZZcRJ38wsI076ZmYZ6TbpSxon6QeSnpD0uKTzU/lekpZJWpP+jkjlknStpA5JqyQdWdrXrLT+GkmzBu+wzLo3Z84cgMMlPVYpk3SppA2SVqbX9NKyi1Jcr5Z0cql8WirrkHRhbY/CrHd6cqW/FfhSREwCjgXmSZoEXAjcFxETgfvSPMApwMT0mgssgOJDArgEOAY4Grik8kFhVg+zZ88GWNPJomsiYnJ6LQVIMT8TOBSYBlwnaYikIcDXKeJ+EtCW1jVrSN0m/YjYGBGPpOnXgSeBMcAM4Ka02k3AqWl6BnBzFJYDwyXtA5wMLIuILRHxCrCM4uQxq4upU6dCcVHTEzOA9oh4JyKeBTooLl6OBjoi4pmI+DXQntY1a0i9atOXNAE4AvgpMDoiNqZFLwCj0/QYYF1ps/WprKtys0ZzXmqaXFT6Nuq4tpbQ46QvaU/gDuCCiHitvCwiAoiBqJCkuZJWSFqxefPmgdilWW8sAA4AJgMbgasHaseObWsEPUr6knahSPi3RMSdqXhTarYh/X0xlW8AxpU2H5vKuirfTkQsjIgpETFl1KhRvTkWs36LiE0RsS0i3gWup2i+gX7Gddq3Y9vqrie9dwTcADwZEX9fWrQEqPTAmQXcVSo/M/XiORZ4NTUD3QOcJGlE+sp8UiozaxiVC5nkNKDSs2cJMFPSMEn7UXRUeBB4CJgoaT9Ju1Lc7F1Syzqb9cbQHqzzceDzwKOSVqayi4ErgNsknQ08B5yeli0FplPc6HoLOAsgIrZIupziJAG4LCK2DMhRmPVBW1sbwCEU1zbrKXqXHS9pMkVz5VrgHICIeFzSbcATFDd/50XENoqNz6O4gBkCLIqIx2t8KGY91m3Sj4gHAHWx+MRO1g9gXhf7WgQs6k0FzQbL4sWLaW9vXxURU0rFN3S1fkTMB+Z3Ur6U4mLHrOH5F7lmZhlx0jczy4iTvplZRpz0zcwy4qRvZpYRJ30zs4w46ZuZZcRJ38wsI076ZmYZcdI3M8uIk76ZWUac9M3MMuKkb2aWESd9M7OMOOmbmWXESd/MLCNO+mZmGXHSNzPLiJO+mVlGnPTNzDLipG9mlhEnfcvWnDlzAA6X9FilTNKVkp6StErStyUNT+UTJP1K0sr0+kZpm6MkPSqpQ9K1klT7ozHrGSd9y9bs2bMB1lQVLwMOi4iPAj8HLiotezoiJqfXuaXyBcAXgInpNW3QKm3WT076lq2pU6cCbC2XRcS9EVEpWw6M3dk+JO0DfCgilkdEADcDpw5Cdc0GhJO+WdfmAHeX5veT9DNJP5J0XCobA6wvrbM+lZk1pKH1roBZI5L01xTfAm5JRRuB8RHxsqSjgO9IOrSX+5wLzAUYP378QFbXrMd8pW9WRdJs4NPAGanJhoh4JyJeTtMPA08DBwEb2L4JaGwq20FELIyIKRExZdSoUYN4BGZdc9I3K5E0Dfgy8JmIeKtUPkrSkDS9P8UN22ciYiPwmqRjU6+dM4G76lB1sx5x845lq62tDeAQQJLWA5dQ9NYZBixLPS+Xp546U4HLJP0GeBc4NyK2pF39OXAjsDvFPYDyfQCzhuKkb9lavHgx7e3tqyJiSqn4hs7WjYg7gDu6WLYCOGwQqmg24Ny8Y2aWESd9M7OMOOmbmWXESd/MLCNO+mZmGXHSNzPLSLdJX9IiSS9WDT97qaQNpWFmp5eWXZSGmF0t6eRS+bRU1iHpwoE/FDMz605PrvRvpPOhYq8pDTO7FEDSJGAmcGja5jpJQ9IvGb8OnAJMAtrSumZmVkPd/jgrIn4saUIP9zcDaI+Id4BnJXUAR6dlHRHxDICk9rTuE72usZmZ9Vl/2vTPS08XWiRpRCobA6wrrVMZZrarcjMzq6G+Jv0FwAHAZIohZ68eqApJmitphaQVmzdvHqjdmpkZfUz6EbEpIrZFxLvA9bzfhLMBGFdatTLMbFflne3bw8+amQ2SPiX99Ii4itOASs+eJcBMScMk7Ucx/OyDwEPAREn7SdqV4mbvkr5X28zM+qLbG7mSFgPHAyNLw88eL2kyEMBa4ByAiHhc0m0UN2i3AvMiYlvaz3nAPcAQYFFEPD7gR2NmZjvVk947bZ0Udzr8bFp/PjC/k/KlwNJe1c7MzAaUf5FrZpYRJ30zs4w46ZuZZcRJ38wsI076ZmYZcdI3M8uIk75la86cOQCHVw0bvpekZZLWpL8jUrkkXZuGBl8l6cjSNrPS+mskzar9kZj1nJO+ZWv27NkAa6qKLwTui4iJwH1pHophwSem11yK8aeQtBfFDxaPoRiO5JLSAIRmDcdJ37I1depUKH45XjYDuClN3wScWiq/OQrLgeFpOJKTgWURsSUiXgGW0fnzJ8wagpO+2fZGR8TGNP0CMDpN93vYcI8ga43ASd+sCxERFONLDdT+PIKs1Z2Tvtn2NlVGkU1/X0zl/R423KwROOmbbW8JUOmBMwu4q1R+ZurFcyzwamoGugc4SdKIdAP3pFRm1pC6HWXTrFW1tbUBHELRI7MybPgVwG2SzgaeA05Pqy8FpgMdwFvAWQARsUXS5RTPjAC4LCK21OwgzHrJSd+ytXjxYtrb21dFxJSqRSdWr5va9+d1tp+IWAQsGoQqmg04N++YmWXESd/MLCNO+mZmGXHSNzPLiJO+mVlGnPTNzDLipG9mlhEnfTOzjDjpm5llxEnfzCwjTvpmZhlx0jczy4iTvplZRpz0zcwy4qRvZpYRJ30zs4w46ZuZZcRJ38wsI076ZmYZcdI3M8tIt0lf0iJJL0p6rFS2l6RlktakvyNSuSRdK6lD0ipJR5a2mZXWXyNp1uAcjln/STpY0srS6zVJF0i6VNKGUvn00jYXpbhfLenketbfbGd6cqV/IzCtquxC4L6ImAjcl+YBTgEmptdcYAEUHxLAJcAxwNHAJZUPCrNGExGrI2JyREwGjgLeAr6dFl9TWRYRSwEkTQJmAodSnCvXSRpSj7qbdafbpB8RPwa2VBXPAG5K0zcBp5bKb47CcmC4pH2Ak4FlEbElIl4BlrHjB4lZIzoReDointvJOjOA9oh4JyKeBTooLm7MGk5f2/RHR8TGNP0CMDpNjwHWldZbn8q6KjdrdDOBxaX581LT5aLSt1XHtzWNft/IjYgAYgDqAoCkuZJWSFqxefPmgdqtWa9J2hX4DHB7KloAHABMBjYCV/dyf45tq7u+Jv1NqdmG9PfFVL4BGFdab2wq66p8BxGxMCKmRMSUUaNG9bF6ZgPiFOCRiNgEEBGbImJbRLwLXM/7TTg9im/HtjWCvib9JUClB84s4K5S+ZmpF8+xwKupGege4CRJI9JX4pNSmVkja6PUtFO50ElOAyo92pYAMyUNk7QfRUeGB2tWS7NeGNrdCpIWA8cDIyWtp+iFcwVwm6SzgeeA09PqS4HpFDey3gLOAoiILZIuBx5K610WEdU3h80ahqQ9gD8AzikV/52kyRTNmWsryyLicUm3AU8AW4F5EbGttjU265luk35EtHWx6MRO1g1gXhf7WQQs6lXtzOokIt4Efruq7PM7WX8+MH+w62XWX/5FrplZRpz0zcwy4qRvZpYRJ30zs4w46ZuZZcRJ38wsI076ZmYZcdI3M8uIk76ZWUac9M3MMuKkb2aWESd9M7OMOOmbmWXESd/MLCNO+mZmGXHSNzPLiJO+mVlGnPTNzDLipG9mlpFun5Fr9TPhwu8N+nusveJTg/4eZtY4fKVvZpYRJ32zTkhaK+lRSSslrUhle0laJmlN+jsilUvStZI6JK2SdGR9a2/WNSd9s679l4iYHBFT0vyFwH0RMRG4L80DnAJMTK+5wIKa19Ssh5z0zXpuBnBTmr4JOLVUfnMUlgPDJe1TjwqadcdJ36xzAdwr6WFJc1PZ6IjYmKZfAEan6THAutK261OZWcNx7x2zzn0iIjZI2htYJump8sKICEnRmx2mD4+5AOPHjx+4mpr1gq/0zToRERvS3xeBbwNHA5sqzTbp74tp9Q3AuNLmY1NZ9T4XRsSUiJgyatSoway+WZec9M2qSNpD0gcr08BJwGPAEmBWWm0WcFeaXgKcmXrxHAu8WmoGMmsobt4x29Fo4NuSoDhHbo2If5X0EHCbpLOB54DT0/pLgelAB/AWcFbtq2zWM076ZlUi4hng8E7KXwZO7KQ8gHk1qJpZv7l5x8wsI076ZmYZcdI3M8uIk76ZWUac9M3MMuKkb2aWkX4lfQ8/a2bWXAbiSt/Dz5qZNYnB+HHWDOD4NH0T8EPgK5SGnwWWSxouaR//XD0PfvSjWWPo75W+h581M2si/b3S9/CzZtYrtfjWB/7m15V+Xel7+Fkzs+bS56Tv4WfNzJpPf5p3PPysmVmT6XPS9/CzZmbNx7/INTPLiJO+mVlGnPTNzDLipG9mlhEnfTOzjDjpm5llxEnfrIqkcZJ+IOkJSY9LOj+VXyppQxpKfKWk6aVtLkrDhq+WdHL9am+2c4MxyqZZs9sKfCkiHkm/On9Y0rK07JqIuKq8sqRJwEzgUOAjwPclHRQR22paa7Me8JW+WZWI2BgRj6Tp14En2fmIsDOA9oh4JyKepfjV+dGDX1Oz3nPSN9sJSROAI4CfpqLz0pPfFlWeCoeHDbcm4qRv1gVJewJ3ABdExGsUT3s7AJgMbASu7uX+5kpaIWnF5s2bB7y+Zj3hpG/WCUm7UCT8WyLiToCI2BQR2yLiXeB63m/C8bDh1jSc9M2qqBg69gbgyYj4+1L5PqXVTqMYShyKYcNnShomaT+K50A/WKv6mvWGe++Y7ejjwOeBRyWtTGUXA22SJlM8JnQtcA5ARDwu6TbgCYqeP/MGo+eOnzNsA8FJ36xKRDwAqJNFS3eyzXxg/qBVymyAuHnHzCwjTvpmZhlx0jczy4iTvplZRpz0zcwy4qRvZpYRJ30zs4w46ZuZZcRJ38wsI076ZmYZcdI3M8uIk76ZWUac9M3MMuKkb2aWESd9M7OMOOmbmWXESd/MLCNO+mZmGXHSNzPLiJO+mVlGnPTNzDJS86QvaZqk1ZI6JF1Y6/c3GwyOa2sWNU36koYAXwdOASYBbZIm1bIOZgPNcW3NpNZX+kcDHRHxTET8GmgHZtS4DmYDzXFtTWNojd9vDLCuNL8eOKa8gqS5wNw0+4ak1TWo10jgpZ6urL8dxJr0X6scS6+OA/p8LPv2aavtdRvXUJfYrtW/YS34WHqny7iuddLvVkQsBBbW8j0lrYiIKbV8z8HSKsfSKsdRVuvYbqV/Qx/LwKl1884GYFxpfmwqM2tmjmtrGrVO+g8BEyXtJ2lXYCawpMZ1MBtojmtrGjVt3omIrZLOA+4BhgCLIuLxWtahCzVtThpkrXIsTXMcjuua8LEMEEVEPd/fzMxqyL/INTPLiJO+mVlGnPTNzDLipG9mlpGG+3HWYJI0FpgQEQ+k+S8Ce6bFt0ZER90qN4AkHQT8VUR8od516QlJHwB+ExG/SfMHA9OB5yLizrpWrknkENvNFtfQmLGd25X+lcDw0vw5wJtAAH9Tlxr1g6SPSrpX0mOSvippH0l3AP8GPFHv+vXCvwITACQdCPwE2B+YJ+l/17FezaRlYruF4hoaMLazutIHDo6I75bm34qIqwEk3V+nOvXH9cACikCaBqwEbgLOiIi361mxXhoREWvS9CxgcUT8Rfqh08PARfWrWtNopdhulbiGBozt3K70d6uaP7E0PbKWFRkgwyLixohYHRH/F3gzIr7chCdG+cciJwDLANKIle/WpUbNp5Viu1XiGhowtnO70n9d0kER8XOAiNgCIOkQ4PW61qxvdpN0BKA0/055PiIeqVvNemeVpKsoxqs5ELgXQNLwnW5lZa0U260S19CAsZ3VL3IlTQOuBeYDlcA5CrgYOD8i7q5X3fpC0g/Z/kqiLCLihBpWp88k7Q6cD+xDMYTBf6Ty3wMOiIh/rmf9mkErxXarxDU0ZmxnlfQBJB0GfBk4NBU9BlwZEY/Vr1YGIGk3iqshKB5K0oxf5+vGsd24Gim2s0v6XZE0PiKer3c9ekPSlyPi79L0H0fE7aVlX4uIi+tXu56TNBT4GnAW8DzF1/hxwDeBv650d7O+abbYbpW4hsaM7dxu5CLpY5L+q6S90/xHJd0K/L86V60vZpamq3sBTKtlRfrpSmAvYP+IOCoijgQOoOiCeFVda9ZEWii2WyWuoQFjO6ukL+lKYBHwR8D3JH2V4sbKT4GJ9axbH6mL6c7mG9mngS9ExHs3HCPiNeDPKH7IYt1osdhulbiGBozt3HrvfAo4IiLeljSC4rmmh0XE2vpWq8+ii+nO5htZRCftjBGxTVIzHUc9tVJst0pcQwPGdm5J/+3KDZSIeEXSmiY9KSoOl/QaxdXP7mmaNF/db7uRPSHpzIi4uVwo6U+Ap+pUp2bTSrHdKnENDRjbWd3IlfRL4MeloqlpXhSfyJ+pS8UyJ2kMcCfwK4pfKQJMAXYHTosIP2+2G47txtSIsZ1b0v/9NLk7RTtnAB0U/yFExI/qVLU+Sd3AzqXoCraKoh/w1vrWqu8kncD73Q2fiIj76lmfZtJKsd1qcQ2NFdu5Jf1dKH68Moei+xQU3aduBC5utq6Bkr4F/Aa4HziFYuS+8+tbq96rOskfBW5o9pO81loptlslrqExYzu3pH8NxXCzX6zcTZf0IYquU29FxAX1rF9vSXo0Iv5zmh4KPJi6hDWVTk7ytc32f1FvrRTbrRLX0JixnVvSXwMcVH03XdIQ4KmIaKqubZIeKZ8M1fPNopVO8npppdhulbiGxozt3HrvNFz3qX6q9HKA7Xs6VG7efah+VeuV95oeImKr1GxdsRtCK8V2q8Q1NGBs55b0G677VH9ExJB612GAtNJJXi8tE9stFNfQgLGdW/NOw3WfMhsIjm3rqaySfkUjdZ8yG0iObetOlknfzCxXWQ24ZmaWOyd9M7OMOOmbmWXESd/MLCNO+mZmGfn/mUapnoOpWpoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "flat_labels = [x_i  for x in true_list for x_i in x]\n",
        "pred_labels = [x_i  for x in pred_list for x_i in x]\n",
        "\n",
        "original_s = pd.Series(flat_labels)\n",
        "predicted_s = pd.Series(pred_labels)\n",
        "\n",
        "stripped_original = original_s.loc[original_s != 'O'].apply(lambda x: x.split('-')[-1])\n",
        "stripped_predicted = predicted_s.loc[predicted_s != 'O'].apply(lambda x: x.split('-')[-1])\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
        "stripped_original.value_counts().sort_index().plot(kind = 'bar', title = 'True Labels', ax=axes[0])\n",
        "stripped_predicted.value_counts().sort_index().plot(kind = 'bar', title = 'Predicted Labels', ax=axes[1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BiLSTM-CRF_Notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}